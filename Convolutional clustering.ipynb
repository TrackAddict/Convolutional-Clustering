{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Input, UpSampling1D, Reshape\n",
    "from keras import Model, Sequential\n",
    "\n",
    "K = keras.backend\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"arcene_data.tsv\", header=None, sep=\" \")\n",
    "\n",
    "labels = pd.read_csv(\"arcene_labels.tsv\", header=None)\n",
    "\n",
    "data = data.fillna(0)\n",
    "\n",
    "data = data.iloc[:, 0:2501]\n",
    "\n",
    "\n",
    "# Joining before train/test split so the labels and data get shuffled together\n",
    "joined = pd.concat((data, labels), axis=1)\n",
    "\n",
    "joined = joined.values\n",
    "\n",
    "#data\n",
    "\n",
    "X_train_, X_test_ = train_test_split(joined, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([78,  0,  0,  0,  0,  0, 19,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0, 11,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting again\n",
    "Y_train = X_train_[:, -1]\n",
    "\n",
    "Y_test = X_test_[:, -1]\n",
    "\n",
    "X_train = X_train_[:, 0:-1]\n",
    "\n",
    "X_test = X_test_[:, 0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is necessary for the way Keras handles inputs, it doesn't change the data at all\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "\n",
    "X_test = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 2501, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of encoded (None, 32)\n",
      "shape of decoded (None, 2501, 1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2501, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 2499, 16)          64        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1249, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1247, 2)           98        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 623, 2)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 621, 32)           224       \n",
      "_________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1 (None, 1242, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 1240, 64)          6208      \n",
      "_________________________________________________________________\n",
      "up_sampling1d_2 (UpSampling1 (None, 2480, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 158720)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2501)              396961221 \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 2501, 1)           0         \n",
      "=================================================================\n",
      "Total params: 396,967,815\n",
      "Trainable params: 396,967,815\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ENCODER\n",
    "input_sig = Input(batch_shape=(None,2501,1))\n",
    "x = Conv1D(16,3, activation='relu', padding='valid')(input_sig)\n",
    "x1 = MaxPooling1D(2)(x)\n",
    "x2 = Conv1D(2,3, activation='relu', padding='valid')(x1)\n",
    "x3 = MaxPooling1D(2)(x2)\n",
    "flat = Flatten()(x3)\n",
    "encoded = Dense(32,activation = 'relu')(flat)\n",
    " \n",
    "print(\"shape of encoded {}\".format(K.int_shape(encoded)))\n",
    " \n",
    "# DECODER \n",
    "x2_ = Conv1D(32, 3, activation='relu', padding='valid')(x3)\n",
    "x1_ = UpSampling1D(2)(x2_)\n",
    "x_ = Conv1D(64, 3, activation='relu', padding='valid')(x1_)\n",
    "upsamp = UpSampling1D(2)(x_)\n",
    "flat = Flatten()(upsamp)\n",
    "decoded = Dense(2501,activation = 'relu')(flat)\n",
    "decoded = Reshape((2501,1))(decoded)\n",
    " \n",
    "print(\"shape of decoded {}\".format(K.int_shape(decoded)))\n",
    " \n",
    "autoencoder = Model(input_sig, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67 samples, validate on 33 samples\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 40s 592ms/step - loss: 165959.0214 - acc: 0.2455 - val_loss: 21254.8929 - val_acc: 0.4606\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 22s 322ms/step - loss: 21088.9317 - acc: 0.4612 - val_loss: 20064.6017 - val_acc: 0.4614\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 23s 350ms/step - loss: 20060.6371 - acc: 0.4624 - val_loss: 19889.8557 - val_acc: 0.4615\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 19992.7050 - acc: 0.4625 - val_loss: 19846.2968 - val_acc: 0.4615\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 19966.6359 - acc: 0.4625 - val_loss: 19882.9062 - val_acc: 0.4615\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 20s 296ms/step - loss: 20000.1349 - acc: 0.4625 - val_loss: 19851.6089 - val_acc: 0.4615\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 20s 301ms/step - loss: 19972.7060 - acc: 0.4625 - val_loss: 19846.7246 - val_acc: 0.4615\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 19s 289ms/step - loss: 19964.5691 - acc: 0.4625 - val_loss: 19824.1432 - val_acc: 0.4616\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 19s 283ms/step - loss: 19947.1621 - acc: 0.4625 - val_loss: 19837.1902 - val_acc: 0.4615\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 19s 288ms/step - loss: 19958.1546 - acc: 0.4625 - val_loss: 19824.2512 - val_acc: 0.4615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2856149aa90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_train, X_train, epochs=10, validation_data=(X_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 623, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This gets the compressed representation (think principle components). The compressed version has 1/2 the features of the full one\n",
    "compressed_layer = 4\n",
    "get_3rd_layer_output = K.function([autoencoder.layers[0].input], [autoencoder.layers[compressed_layer].output])\n",
    "compressed = get_3rd_layer_output([X_test])[0]\n",
    "\n",
    "np.shape(compressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation = compressed.reshape(33, 623*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-e2ea73bb3b4c>:11: KMeansClustering.__init__ (from tensorflow.contrib.learn.python.learn.estimators.kmeans) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.contrib.factorization.KMeansClustering instead of tf.contrib.learn.KMeansClustering. It has a similar interface, but uses the tf.estimator.Estimator API instead of tf.contrib.learn.Estimator.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:1179: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:427: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Michael\\AppData\\Local\\Temp\\tmp_hldudjb\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000285639B9748>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\Michael\\\\AppData\\\\Local\\\\Temp\\\\tmp_hldudjb'}\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\kmeans.py:151: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Michael\\AppData\\Local\\Temp\\tmp_hldudjb\\model.ckpt.\n",
      "INFO:tensorflow:loss = 21469922.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 864.368\n",
      "INFO:tensorflow:loss = 11858978.0, step = 101 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 2228.13\n",
      "INFO:tensorflow:loss = 11858986.0, step = 201 (0.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 2005.38\n",
      "INFO:tensorflow:loss = 11858970.0, step = 301 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2278.83\n",
      "INFO:tensorflow:loss = 11858990.0, step = 401 (0.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 2278.79\n",
      "INFO:tensorflow:loss = 11858990.0, step = 501 (0.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 2331.8\n",
      "INFO:tensorflow:loss = 11858984.0, step = 601 (0.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 2228.17\n",
      "INFO:tensorflow:loss = 11858977.0, step = 701 (0.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 2278.79\n",
      "INFO:tensorflow:loss = 11858974.0, step = 801 (0.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 2331.81\n",
      "INFO:tensorflow:loss = 11858978.0, step = 901 (0.044 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\Michael\\AppData\\Local\\Temp\\tmp_hldudjb\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 11858970.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeansClustering(params={'num_clusters': 2, 'training_initial_clusters': 'random', 'distance_metric': 'squared_euclidean', 'random_seed': 0, 'use_mini_batch': True, 'mini_batch_steps_per_iteration': 1, 'kmeans_plus_plus_num_retries': 2, 'relative_tolerance': None})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training K-Means\n",
    "from tensorflow.contrib.factorization.python.ops import clustering_ops\n",
    "import tensorflow as tf\n",
    " \n",
    "def train_input_fn():\n",
    "    data = tf.constant(representation, tf.float32)\n",
    "    return (data, None)\n",
    " \n",
    "unsupervised_model = tf.contrib.learn.KMeansClustering(\n",
    "2 #num of clusters\n",
    ", distance_metric = clustering_ops.SQUARED_EUCLIDEAN_DISTANCE\n",
    ", initial_clusters=tf.contrib.learn.KMeansClustering.RANDOM_INIT\n",
    ")\n",
    " \n",
    "unsupervised_model.fit(input_fn=train_input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Michael\\AppData\\Local\\Temp\\tmp_hldudjb\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "#Getting clusters for data points\n",
    "clusters = unsupervised_model.predict(input_fn=train_input_fn)\n",
    "predicted = []\n",
    " \n",
    "index = 0\n",
    "for i in clusters:\n",
    "    current_cluster = i['cluster_idx']\n",
    "    predicted.append(current_cluster)\n",
    "    features = X_test[index]\n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing from 1vs0 classes to 1vs-1\n",
    "predicted = [x if x==1 else -1 for x in predicted]\n",
    "\n",
    "predicted = np.asarray(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1, -1, -1, -1, -1, -1,  1, -1,  1, -1,  1, -1, -1,  1, -1, -1,\n",
       "        1, -1,  1, -1, -1,  1, -1,  1,  1,  1, -1, -1, -1,  1, -1, -1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAE is 60.60606060606061% accurate\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] == Y_test[i]:\n",
    "        score += 1\n",
    "        \n",
    "percent = (score / len(predicted))*100\n",
    "\n",
    "print(\"CAE is {}% accurate\".format(percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
